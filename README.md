# ğŸš€ Full MCP Chatbot (Multi-Server MCP Client)

A **multi-tool AI chatbot** built using **LangChain + MCP (Model Context Protocol)** that connects to **multiple MCP servers**, reasons over user queries, and automatically invokes the correct tools.

This project is designed as a **reference implementation** for building real-world agentic systems using MCP.

---

## âœ¨ Features

- ğŸ”— Connects to **multiple MCP servers** at once  
- ğŸ§  Automatic **tool selection & execution**
- ğŸ’¬ Clean **Streamlit chat interface**
- âš™ï¸ Fully **async** architecture
- ğŸ”’ Secure API key loading via `.env`
- ğŸ§© Easily extensible MCP server config

---

## ğŸ—ï¸ Architecture
```bash
User
 â†“
Streamlit Chat UI
 â†“
LangChain Agent (Gemini)
 â†“
MultiServerMCPClient
 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Math MCP      â”‚   â”‚ Expense MCP       â”‚
â”‚ (stdio)       â”‚   â”‚ (HTTP)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

The agent:
- Reads user input
- Decides whether a tool is required
- Calls the correct MCP tool
- Returns a clean final answer

---

## ğŸ“‚ Project Structure
```bash
.
â”œâ”€â”€ main.py              # CLI-based MCP agent runner
â”œâ”€â”€ streamlit_app.py     # Streamlit chat UI
â”œâ”€â”€ pyproject.toml       # Project metadata & dependencies
â”œâ”€â”€ .env                 # API keys (add your api keys)
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ§  MCP Servers

### 1ï¸âƒ£ Math MCP (Local â€“ stdio)
- Used for math & computational tasks
- Runs via `fastmcp`

### 2ï¸âƒ£ Expense Tracker MCP (Remote â€“ HTTP)
- Hosted MCP server
- Used for expense queries and summaries

Both are configured in the `SERVERS` dictionary inside the client.

---

## ğŸ”‘ Environment Setup

Create a `.env` file in the root directory:

```env
GOOGLE_API_KEY=your_google_gemini_api_key
```

## ğŸ“¦ Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/your-username/full-mcp-chatbot.git
cd full-mcp-chatbot
````

### 2ï¸âƒ£ Install dependencies

**Using pip**

```bash
pip install -r requirements.txt
```

**Using uv**

```bash
uv sync
```

Dependencies are defined in `pyproject.toml`.

---

## â–¶ï¸ Running the Project

### ğŸ”¹ Run CLI Agent

```bash
python main.py
```

Used for debugging and single-prompt testing.

---

Note: before run make sure you change the servers according to your project

### ğŸ”¹ Run Streamlit Chat UI

```bash
streamlit run main.py
```

Launches a browser-based MCP-powered chatbot.

---

## ğŸ§ª Tool Execution Flow

1. User sends a prompt
2. LLM checks if a tool is required
3. MCP tool is invoked
4. Tool result is injected back
5. Final response is returned

Intermediate tool-thinking steps are hidden for a clean UI.

---

## ğŸ§© Adding a New MCP Server

Add a new entry to the `SERVERS` config:

```python
SERVERS["new_server"] = {
    "transport": "streamable_http",
    "url": "https://your-mcp-server/mcp"
}
```

No agent logic changes required.

---

## ğŸ› ï¸ Tech Stack

* Python 3.12+
* LangChain
* Model Context Protocol (MCP)
* Google Gemini
* Streamlit
* FastMCP

---

## ğŸ¯ Use Cases

* Agentic AI systems
* Tool-augmented chatbots
* MCP experimentation
* LangChain + MCP learning
* Multi-tool orchestration demos

---

## ğŸ› ï¸ Contributing

1. Fork the repository  
2. Create a feature branch  
3. Commit and push changes  
4. Open a Pull Request  



https://github.com/user-attachments/assets/8b4b979a-a80c-410a-b436-ee675a58e1f6

